{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90791,"databundleVersionId":10592855,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Problem Statement: predict a system’s probability of getting infected by various families of malware, based on different properties of that system. The telemetry data containing these properties and the system infections was generated by threat reports collected by system's antivirus software.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\nfrom category_encoders import TargetEncoder, CountEncoder\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n### Loading Dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/System-Threat-Forecaster/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/System-Threat-Forecaster/test.csv\")\nsubmission_data = pd.read_csv(\"/kaggle/input/System-Threat-Forecaster/sample_submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"print(\"\\nTrain Data Info:\")\ntrain_data.info()","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nTest Data Info:\")\ntest_data.info()","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.shape,test_data.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check for missing values","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = train_data.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending=False)\nprint(\"\\nMissing Values in Train Data:\")\nprint(missing_values)\n\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values\nmissing_values = test_data.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending=False)\nprint(\"\\nMissing Values in Train Data:\")\nprint(missing_values)","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Summary statistics of numerical features\nprint(\"\\nNumerical Feature Summary:\")\npd.set_option(\"display.max_columns\", None)  # Show all columns\npd.set_option(\"display.max_rows\", None)\nprint(train_data.describe())","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check unique values in each column\nunique_values = train_data.nunique()\nunique_values = unique_values[unique_values > 0].sort_values(ascending=False)\nprint(\"\\nUnique Values per Column in Train Data:\")\nprint(unique_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyze target distribution\nplt.figure(figsize=(6,4))\nsns.countplot(x=train_data['target'])\nplt.title(\"Target Distribution\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['target'].value_counts(normalize=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*Target variable is balanced*","metadata":{}},{"cell_type":"code","source":"cat_cols = ['ProductName', 'EngineVersion','PlatformType', 'Processor', 'OSVersion',\n       'OsPlatformSubRelease', 'SKUEditionName',\n       'MDC2FormFactor', 'DeviceFamily', 'PrimaryDiskType', 'ChassisType',\n       'PowerPlatformRole', 'OSArchitecture', 'OSBranch',\n       'OSEdition', 'OSSkuFriendlyName', 'OSInstallType',\n       'AutoUpdateOptionsName', 'OSGenuineState', 'LicenseActivationChannel',\n       'FlightRing']\nfor col in cat_cols:\n    plt.figure(figsize=(8,4))\n    sns.countplot(y=train_data[col], order=train_data[col].value_counts().index)\n    plt.title(f'Distribution of {col}')\n    plt.show()\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = ['IsBetaUser', 'RealTimeProtectionState', 'IsPassiveModeEnabled',\n       'AntivirusConfigID', 'NumAntivirusProductsInstalled',\n       'NumAntivirusProductsEnabled', 'HasTpm', 'CountryID', 'CityID',\n       'GeoRegionID', 'LocaleEnglishNameID', 'OSBuildNumber', 'OSProductSuite',\n       'IsSystemProtected', 'AutoSampleSubmissionEnabled', 'SMode',\n       'IEVersionID', 'FirewallEnabled', 'EnableLUA', 'OEMNameID',\n       'OEMModelID', 'ProcessorCoreCount', 'ProcessorManufacturerID',\n       'ProcessorModelID', 'PrimaryDiskCapacityMB', 'SystemVolumeCapacityMB',\n       'HasOpticalDiskDrive', 'TotalPhysicalRAMMB',\n       'PrimaryDisplayDiagonalInches', 'PrimaryDisplayResolutionHorizontal',\n       'PrimaryDisplayResolutionVertical', 'InternalBatteryNumberOfCharges',\n       'OSBuildNumberOnly', 'OSBuildRevisionOnly', 'OSInstallLanguageID',\n       'OSUILocaleID', 'IsPortableOS', 'IsFlightsDisabled',\n       'FirmwareManufacturerID', 'FirmwareVersionID', 'IsSecureBootEnabled',\n       'IsVirtualDevice', 'IsTouchEnabled', 'IsPenCapable',\n       'IsAlwaysOnAlwaysConnectedCapable', 'IsGamer', 'RegionIdentifier',\n       'target']\nfig, axes = plt.subplots(5, 5, figsize=(15, 12))  # Grid of subplots\n\nfor i, col in enumerate(num_cols[:25]):  # First 25 numerical columns\n    row, col_index = divmod(i, 5)  # Compute row & column index\n    axes[row, col_index].hist(train_data[col], bins=50, edgecolor='black', alpha=0.7)\n    axes[row, col_index].set_title(col, fontsize=10)\n\nfig.tight_layout(pad=2.0)  # Add spacing between subplots\nplt.show()\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = train_data.select_dtypes(exclude = \"object\").columns\nnum_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation of numerical features with target\ncorrelation = train_data[num_cols].corr()['target'].sort_values(ascending=False)\nprint(\"\\nFeature Correlation with Target:\")\nprint(correlation)","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*There is not Linear relationship between features and target columns, hence in that case linear models may not work*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n  # Replace with your actual dataset\n\n# Compute correlation matrix\ncorrelation_matrix = train_data[num_cols].corr()\n\n# Find the two columns with the highest absolute correlation (excluding self-correlation)\ncorrelation_matrix = correlation_matrix.abs()\nnp.fill_diagonal(correlation_matrix.values, 0)  # Ignore self-correlation\n\n# Get the highest correlated pair\nmax_corr = correlation_matrix.unstack().idxmax()\nprint(f\"Highest correlation is between: {max_corr[0]} and {max_corr[1]}\")\nprint(f\"Correlation value: {correlation_matrix.loc[max_corr[0], max_corr[1]]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert Date Features to datetime format\ntrain_data['DateAS'] = pd.to_datetime(train_data['DateAS'])\ntrain_data['DateOS'] = pd.to_datetime(train_data['DateOS'])\n\ntest_data['DateAS'] = pd.to_datetime(test_data['DateAS'])\ntest_data['DateOS'] = pd.to_datetime(test_data['DateOS'])\n\n# Extract useful date-based features\ntrain_data['AS_Year'] = train_data['DateAS'].dt.year\ntrain_data['OS_Year'] = train_data['DateOS'].dt.year\ntrain_data['AS_Month'] = train_data['DateAS'].dt.month\ntrain_data['OS_Month'] = train_data['DateOS'].dt.month\ntrain_data['Days_Diff'] = (train_data['DateAS'] - train_data['DateOS']).dt.days\n\ntest_data['AS_Year'] = test_data['DateAS'].dt.year\ntest_data['OS_Year'] = test_data['DateOS'].dt.year\ntest_data['AS_Month'] = test_data['DateAS'].dt.month\ntest_data['OS_Month'] = test_data['DateOS'].dt.month\ntest_data['Days_Diff'] = (test_data['DateAS'] - test_data['DateOS']).dt.days","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1.There are many null values.\n2. There are consant columns.\n3. Have higher correlation between 2 columns.\n4.There is no correlation between target and other numerical features.\n5. Categorical columns contaion UNKNOWN values and numerical columns contains outliears.* **","metadata":{}},{"cell_type":"markdown","source":"## Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# Handling missing values\ntrain_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_col = train_data.select_dtypes(include = \"object\").columns\ncat_col","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nID_col = [\"CityID\",\"IsVirtualDevice\",\"SMode\",\"FirewallEnabled\",\"NumAntivirusProductsEnabled\",\"NumAntivirusProductsInstalled\",\"IsAlwaysOnAlwaysConnectedCapable\",\"IsFlightsDisabled\",\"IsGamer\",\"EnableLUA\",\"RealTimeProtectionState\",\"FirmwareManufacturerID\",\"FirmwareVersionID\",\"OEMModelID\",\"OEMNameID\",\"OSInstallLanguageID\",\"ProcessorModelID\",\"ProcessorManufacturerID\",\"AntivirusConfigID\",\"IEVersionID\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_id_col = list(cat_col) + ID_col","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_col = [\"RegionIdentifier\", \"InternalBatteryNumberOfCharges\", \"IsSystemProtected\",\n                 \"TotalPhysicalRAMMB\", \"PrimaryDiskCapacityMB\", \"SystemVolumeCapacityMB\",\n                 \"ProcessorCoreCount\", \"PrimaryDisplayResolutionHorizontal\", \n                 \"PrimaryDisplayResolutionVertical\", \"PrimaryDisplayDiagonalInches\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define imputers\ncat_id_imputer = SimpleImputer(strategy=\"most_frequent\")  # Combined categorical + ID imputer\nnum_imputer = SimpleImputer(strategy=\"mean\")  # Numerical imputer\n\n# Column transformer to handle different imputations\npreprocessor = ColumnTransformer([\n    (\"cat_id_impute\", cat_id_imputer, cat_id_col),\n    (\"num_impute\", num_imputer, num_col)\n], remainder=\"passthrough\") #what does this mean find out.\n\n# Create pipeline\nimpute_pipeline = Pipeline([\n    (\"preprocess\", preprocessor)\n])\n\n# Apply transformation\ntrain_data[cat_id_col + num_col] = impute_pipeline.fit_transform(train_data[cat_id_col + num_col])\ntest_data[cat_id_col + num_col] = impute_pipeline.transform(test_data)\n\n# Fill specific columns with fixed values\nfill_values = {\n    \"DateOS\": \"2018-08-14\", \"OS_Year\": \"2018.0\", \"OS_Month\": \"8.0\", \"Days_Diff\": \"14.0\",\n    \"DateAS\": \"2018-08-14\", \"AS_Year\": \"2018.0\", \"AS_Month\": \"8.0\"\n}\n\ntrain_data.fillna(fill_values, inplace=True)\ntest_data.fillna(fill_values, inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = train_data.drop(columns = [\"DateOS\",\"DateAS\"])\ntest_data = test_data.drop(columns = [\"DateOS\",\"DateAS\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values\nmissing_values = test_data.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending=False)\nprint(\"\\nMissing Values in Train Data:\")\nprint(missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data[\"GeoRegionID\"] = test_data[\"GeoRegionID\"].fillna(277.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.isna().sum().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find constant columns (only 1 unique value)\nconstant_cols = [col for col in train_data.columns if train_data[col].nunique() == 1]\n\nprint(\"Constant Columns:\", constant_cols)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = train_data.drop(columns =  ['IsBetaUser', 'AutoSampleSubmissionEnabled', 'IsFlightsDisabled'])\ntest_data = test_data.drop(columns =  ['IsBetaUser', 'AutoSampleSubmissionEnabled', 'IsFlightsDisabled'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Columns Encoding","metadata":{}},{"cell_type":"code","source":"\n# Define categorical columns for encoding\none_hot_cols = [\"PlatformType\", \"Processor\", \"OSGenuineState\", \"OSArchitecture\", \"DeviceFamily\", \"OSInstallType\", \"OsPlatformSubRelease\", \"SKUEditionName\", \"PrimaryDiskType\", \"PowerPlatformRole\", \"AutoUpdateOptionsName\", \"LicenseActivationChannel\", \"FlightRing\", \"MDC2FormFactor\", \"OSBranch\"]\ncount_enc_cols = [\"EngineVersion\", \"AppVersion\"]\ntarget_enc_cols = [\"SignatureVersion\", \"OSBuildLab\", \"NumericOSVersion\", \"OSEdition\", \"OSSkuFriendlyName\", \"ChassisType\"]\nordinal_enc_cols = [\"ProductName\", \"MachineID\"]\nos_version_col = \"OSVersion\"\n\n# Define OS version mapping\nos_order = ['6.1.1.0', '6.3.0.0', '10.0.0.0', '10.0.1.0', '10.0.2.0', '10.0.3.0', '10.0.4.0']\nos_mapping = {version: idx for idx, version in enumerate(os_order)}\n\n# Define transformers\none_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\ncount_encoder1 = CountEncoder()\ntarget_encoder1 = TargetEncoder()\nordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n\n# Preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"onehot\", one_hot_encoder, one_hot_cols),\n        (\"count_enc_1\", count_encoder1, count_enc_cols),\n        (\"target_enc_1\", target_encoder1, target_enc_cols),\n        (\"ordinal_enc\",ordinal_encoder,ordinal_enc_cols)\n    ],\n    remainder=\"passthrough\"\n)\n\n# Complete pipeline\npipeline = Pipeline([\n    (\"preprocessor\", preprocessor)\n])\n\n# Apply pipeline to train and test data\n# Apply pipeline to train and test data (excluding target column)\ntrain_features = train_data.drop(columns=['target'])  # Drop target for transformation\ntrain_D = pipeline.fit_transform(train_features, train_data['target'])\ntest_D = pipeline.transform(test_data)\n\n\n# Convert transformed NumPy array back to DataFrame\ntrain_D = pd.DataFrame(train_D, columns=pipeline.get_feature_names_out())\ntest_D = pd.DataFrame(test_D, columns=pipeline.get_feature_names_out())\n\n# Convert OSVersion using mapping\ntrain_D[\"OSVersion_encoded\"] = train_data[\"OSVersion\"].map(os_mapping).values\ntest_D[\"OSVersion_encoded\"] = test_data[\"OSVersion\"].map(os_mapping).values\n\ntrain_D = train_D.drop(columns = \"remainder__OSVersion\")\ntest_D = test_D.drop(columns = \"remainder__OSVersion\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_D[\"remainder__OS_Year\"] = train_D[\"remainder__OS_Year\"].astype(float)\ntrain_D[\"remainder__OS_Month\"] = train_D[\"remainder__OS_Month\"].astype(float)\ntrain_D[\"remainder__Days_Diff\"] = train_D[\"remainder__Days_Diff\"].astype(float)  # Use int if all values are whole numbers\n\ntest_D[\"remainder__AS_Year\"] = test_D[\"remainder__AS_Year\"].astype(float)\ntest_D[\"remainder__AS_Month\"] = test_D[\"remainder__AS_Month\"].astype(float)\n#test_D[\"remainder__OS_Year\"] = test_D[\"remainder__OS_Year\"].astype(float)  # Use int if all values are whole numbers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert all object columns that contain numbers into numeric types\nfor col in train_D.select_dtypes(include=['object']).columns:\n    train_D[col] = pd.to_numeric(train_D[col], errors='coerce') # Converts to float if needed\nfor col in test_D.select_dtypes(include=['object']).columns:\n    test_D[col] = pd.to_numeric(test_D[col], errors='coerce')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_D.select_dtypes(include  = \"object\").columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Selection and Scaling","metadata":{}},{"cell_type":"code","source":"X = train_D\nY = train_data[\"target\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Scaling Features**","metadata":{}},{"cell_type":"code","source":"# Standardize Features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X)\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n#X_test_scaled = scaler.transform(test_data)\nX_test_scaled = scaler.transform(test_D)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=test_D.columns)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature Selection**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train_scaled, Y)\nfeature_importance = pd.Series(model.feature_importances_, index=X.columns)\nimportant_features = feature_importance[feature_importance > 0.01].index\ntrain_selected2 = X_train_scaled[important_features]\ntest_selected2 =  X_test_scaled[important_features]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, mutual_info_classif\nselector = SelectKBest(mutual_info_classif, k=10)  # Select top 10 features\ntrain_selected3 = selector.fit_transform(X_train_scaled, Y)\ntest_selected3 = selector.transform(X_test_scaled)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train XGBClassifier\nxgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\nxgb.fit(X_train, y_train)\n\n# Select important features\nselector = SelectFromModel(xgb, prefit=True)\ntrain_selected4 = selector.transform(X_train_scaled)\ntest_selected4 = selector.transform(X_test_scaled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_selected4.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Split Data\nX_train, X_test, Y_train, Y_test = train_test_split(train_selected2, Y, test_size=0.2, random_state=42)\n\n# Train Model\nmodel1 = RandomForestClassifier()\nmodel1.fit(X_train, Y_train)\n\nfrom sklearn.metrics import mean_squared_error\ny_val_pred = model1.predict(X_test)\n# Evaluate model performance\nmse = mean_squared_error(Y_test, y_val_pred)\nprint(f\"Validation MSE: {mse}\")\ny_pred1 = model1.predict(test_selected2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nX_train, X_test, Y_train, Y_test = train_test_split(train_selected3, Y, test_size=0.2, random_state=42)\nmodel2 = LogisticRegression()\nmodel2.fit(X_train, Y_train)\n\ny_val_pred = model2.predict(X_test)\nmse = mean_squared_error(Y_test, y_val_pred)\nprint(f\"Validation MSE: {mse}\")\n\n# ✅ Step 4: Predict Values\ny_pred2 = model2.predict(test_selected3)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier \n# Train XGBoost model\nX_train, X_test, Y_train, Y_test = train_test_split(train_selected4, Y, test_size=0.2, random_state=42)\nmodel3 = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\nmodel3.fit(X_train, Y_train)\n\ny_val_pred = model3.predict(X_test)\nmse = mean_squared_error(Y_test, y_val_pred)\nprint(f\"Validation MSE: {mse}\")\n# Predictions\ny_pred3 = model3.predict(test_selected4)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\nx_train,x_test,y_train,y_test = train_test_split(train_selected4,Y,test_size = 0.2)\n\nparam_dist = {\n    'max_depth': np.random.randint(3, 10, 5),\n    'learning_rate': np.linspace(0.01, 0.2, 10),\n    'n_estimators': np.random.randint(100, 500, 10)\n}\n\nrandom_search = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n                                   param_dist, n_iter=10, scoring='accuracy', cv=5, verbose=2)\nrandom_search.fit(train_selected4,Y)\n\nprint(random_search.best_params_)\nbest_xgbclassifier_model = random_search.best_estimator_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred4 = best_xgbclassifier_model.predict(test_selected4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_test = submission_data[\"target\"].values  # Extract target values\nY_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nacc1 = print(\"RandomClassifier Accuracy:\",accuracy_score(Y_test,y_pred1))\nacc2 = print(\"Logistic Accuracy:\",accuracy_score(Y_test,y_pred2))\nacc3 = print(\"XGBClassifier:\",accuracy_score(Y_test,y_pred3))\nacc4 = print(\"Best_XGBClassifier:\",accuracy_score(Y_test,y_pred4))\nprint(classification_report(Y_test,y_pred4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test,y_pred4)\n\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred 0', 'Pred 1'], yticklabels=['Actual 0', 'Actual 1'])\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nprint(\"Precision Score:\",precision_score(Y_test,y_pred4))\nprint(\"Recall Score:\",recall_score(Y_test,y_pred4))\nprint(\"f1 Score:\",f1_score(Y_test,y_pred4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({'id': range(0,test_data.shape[0]),'target':y_pred4})\nsubmission.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}